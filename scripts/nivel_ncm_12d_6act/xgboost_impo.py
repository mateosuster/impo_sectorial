# -*- coding: utf-8 -*-
"""xgboost_impo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16uujRCNtIfMg4ZoV-JQxtFRMEqnn3l4I

# Librerias
"""
import os
os.chdir("C:/Users/Administrator/Documents/equipo investigacion/impo_sectorial/scripts/nivel_ncm_12d_6act")

import pandas as pd
from numpy import array

import matplotlib.pyplot as plt


from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score#, scorer
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score
from sklearn.metrics import mean_absolute_error

from urllib.request import urlretrieve

import xgboost as xgb
# from xgboost import XGBClassifier

"""# Datos"""

data_pre = pd.read_csv( "../data/resultados/data_train_test.csv")#.drop(U)
data_pre.head()
data_pre.shape

# data_pre.dropna(inplace=True)

# data_pre.dropna(inplace=True)
data_pre=data_pre.sample( n = 1000, random_state = 42 )
data_pre.shape

X_train , X_test, y_train, y_test = train_test_split(data_pre.drop("bk_dummy", axis =1), 
                                                     data_pre["bk_dummy"], test_size = 0.3, random_state = 3)

"""## Modelo de base"""

classifier = xgb.sklearn.XGBClassifier(nthread=-1, seed=42)

classifier.fit(X_train, y_train)

print("Number of boosting trees: {}".format(classifier.n_estimators))
print("Max depth of trees: {}".format(classifier.max_depth))
print("Objective function: {}".format(classifier.objective))

y_pred = classifier.predict(X_test)
pd.DataFrame(y_pred, index=X_test.index, columns=['bk_dummy']).value_counts()

roc_auc_score(y_test,y_pred)

confusion_matrix(y_test, y_pred, normalize= "pred")#, labels= [1, 0 ])

print(classification_report(y_test, y_pred) )

plt.figure(figsize=(20,15))
xgb.plot_importance(classifier, ax=plt.gca())

plt.figure(figsize=(20,15))
xgb.plot_tree(classifier, ax=plt.gca())

"""## Random y Grid Search


"""

classifier = xgb.sklearn.XGBClassifier(nthread=-1, objective= 'binary:logistic', seed=42)

# parameters = {
#     'max_depth': range (2, 10, 1),
#     'n_estimators': range(60, 220, 40),
#     'learning_rate': [0.1, 0.01, 0.05]
# }

parameters = {'silent': [False],
        'max_depth':  range (2, 10, 1),
        'learning_rate': [0.1, 0.01, 0.05],
        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],
        'gamma': [0, 0.25, 0.5, 1.0],
        'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],
        'n_estimators': range(60, 220, 40),
        }

# grid_search = GridSearchCV(
#     estimator=classifier,
#     param_grid=parameters,
#     scoring = 'roc_auc',
#     n_jobs = 10,
#     cv = 10,
#     verbose=True
# )

random_search = RandomizedSearchCV(
    estimator=classifier,
    param_distributions=parameters,
    scoring = 'roc_auc',
    n_jobs = 10,
    cv = 10,                        
    verbose=True
)

# grid_search.fit(X_train, y_train)
random_search.fit(X_train, y_train)

best_xgb = random_search.best_estimator_
best_xgb

y_pred = best_xgb.predict(X_test)
pd.DataFrame(y_pred, index=X_test.index, columns=['bk_dummy']).value_counts()

# plt.hist( y_pred["bk_dummy"])

roc_auc_score(y_test,y_pred)

confusion_matrix(y_test, y_pred, normalize= "pred")#, labels= [1, 0 ])

print(classification_report(y_test, y_pred) )

plt.figure(figsize=(20,15))
xgb.plot_importance(best_xgb, ax=plt.gca())

"""## Entrenamiento con todos los datos"""

xgboos_rscv_all = RandomizedSearchCV(
    estimator=classifier,
    param_distributions=parameters,
    scoring = 'roc_auc',
    n_jobs = 10,
    cv = 10,                          
    verbose=True)

xgboos_rscv_all.fit(data_pre.drop("bk_dummy", 1), data_pre["bk_dummy"]   )

best_xgb = xgboos_rscv_all.best_estimator_
best_xgb

"""### Predicci√≥n de nuevas observaciones"""

data_2pred = pd.read_csv("../data/resultados/data_to_pred.csv")
data_2pred.head()

data_2pred.info()

clasificacion = best_xgb.predict(data_2pred)
clasificacion_df = pd.DataFrame(clasificacion, columns= ["bk_dummy"])
clasificacion_df.value_counts()

plt.hist(x = "bk_dummy", data = clasificacion_df)

for boolean , text in zip([True, False], ["Frecuencias Relativas", "Frecuencias Abosolutas"] ):
  print(text+"\n", clasificacion_df.bk_dummy.value_counts(normalize= boolean), "\n" )